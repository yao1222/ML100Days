# D7: 特徵類型





## 常見特徵類型



### 數值型

補充資料: https://ithelp.ithome.com.tw/articles/10219949?sc=hot



之前我們可能會執行填補缺失值(ex. fillna, SimpleImputer)或直接去除離群值



但還有一個方法就是"去偏態"，其實就是讓原本為左偏或右偏的數據資料可以符合我們的"常態假設"

處理方法:

1.對數去偏(log1p)

2.⽅根去偏(sqrt)

3.分布去偏(boxcox)



### 類別型



處理方法:

1. 標籤編碼 (Label Encoding)

2. 獨熱編碼 (One Hot Encoding)
3. 均值編碼 (Mean Encoding)
4. 計數編碼 (Counting)
5. 特徵雜湊 (Feature Hash)



### 時間型

處理方法:

1. 時間特徵分解
2. 週期循環特徵





## 其他特徵類型





| 特徵類型 | 處理方法                         |
| -------- | -------------------------------- |
| 數值型   | 上面有提                         |
| 類別型   | 上面有提                         |
| 時間型   | 上面有提                         |
| 文本型   | TF-IDF、詞袋、word2vec           |
| 統計型   | 比率、次序、加減乘除平均、分位數 |
| 其他類型 | 組合特徵                         |





## Cross Validation







#### 1. 交叉驗證(Cross validation)是什麼?


簡單來說就是將整個數據集(Dataset)切成許多集(組)，一部份的組作為訓練集，另一部分做為測試集，達到訓練與評價模型的效果

#### 2. 為什麼需要交叉驗證?

a. 如果我們只用一組的訓練集來訓練模型，會導致我們的結果可能會有偏差，也就是換了訓練集資料後，訓練出來的模型預測能力可能不同，但都是源自同一個資料集來創建模型，更有效的方法是，將不同的資料組輪流成為訓練集，然後平均得出來的結果，就能更客觀的了解模型的預測能力
b. 我們的數據集不夠大量，有限的資源下要獲得更多的資訊 
c. 可以找到合適的模型或參數，像是找到KNN中符合資料的K值，讓機器學習模型表現最好



#### 3. 交叉驗證的方法?

> a.留出法 (holdout cross validation)
> b. k折交叉驗證法 (k-fold Cross Validation)
> c.留一法 (Leave one out cross validation) 
> d. Bootstrap Sampling





### LOOCV

只用一個數據當測試集，其他全為訓練集



### K-fold Cross Validation

以k=5為例，將所有數據集切成五等分，不重復的選其中一份當測試集，其他當訓練集，並計算模型在測試集上的MSE

